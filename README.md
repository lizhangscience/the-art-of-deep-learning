The Art of Deep-Learning 
==============



**Adversarial Attacks:**
 * (Szegedy; L-BFGS) Intriguing properties of neural networks [link](https://arxiv.org/abs/1312.6199) 
 * (FGS) Explaining and harnessing adversarial examples [link](https://arxiv.org/abs/1412.6572)
 * Adversarial Manipulation of Deep Representations [link](https://arxiv.org/abs/1511.05122)
 * ADVERSARIAL EXAMPLES IN THE PHYSICAL WORLD (iterative methods) [link](https://arxiv.org/abs/1607.02533)
 * Adversarial machine learning at scale [link](https://arxiv.org/abs/1611.01236)
 * (hot/cold) Adversarial diversity and hard positive generation [link](https://arxiv.org/abs/1605.01775)
 * Assessing Threat of Adversarial Examples on Deep Neural Network [link](https://arxiv.org/abs/1610.04256)
 * Simple Black-Box Adversarial Perturbations for Deep Networks [link](https://arxiv.org/abs/1612.06299)
 * Are Facial Attributes Adversarially Robust? [link](https://arxiv.org/abs/1605.05411)

**Defense Against Adversarial Attacks (Adversarial Robustness)**
 * Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks [link](https://arxiv.org/abs/1709.03423)
 * Adversarial robustness: Softmax versus Openmax [link](https://arxiv.org/abs/1708.01697)
 * Towards Robust Deep Neural Networks with BANG [link](https://arxiv.org/abs/1612.00138)
 * Ensemble Adversarial Training: Attacks and Defenses [link](https://arxiv.org/abs/1705.07204)
 * Robustness of classifiers: from adversarial to random noise [link](https://arxiv.org/abs/1608.08967)
 * Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation [link](https://arxiv.org/abs/1705.08475)
 * Lower bounds on the robustness to adversarial perturbations [link](https://papers.nips.cc/paper/6682-lower-bounds-on-the-robustness-to-adversarial-perturbations)
 * Improving the Robustness of Deep Neural Networks via Stability Training [link](https://arxiv.org/abs/1604.04326)
 * Towards Deep Neural Network Architectures Robust to Adversarial Examples [link](https://arxiv.org/abs/1412.5068)
 * Foveation-based Mechanisms Alleviate Adversarial Examples [link](https://arxiv.org/abs/1511.06292)
 * Adversarial Logit Pairing [link](https://arxiv.org/abs/1803.06373)
 * Towards deep learning models resistant to adversarial attacks [link](https://arxiv.org/abs/1706.06083)



